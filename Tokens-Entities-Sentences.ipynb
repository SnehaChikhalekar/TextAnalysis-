{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracts the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    corpus=open(\"transcript_clean_new.txt\",\"r\",encoding=\"utf-8\").read()\n",
    "    \n",
    "    #nlp=spacy.load(\"es_core_news_md\")\n",
    "    \n",
    "    nlp.max_length=len(corpus)\n",
    "    \n",
    "    doc=nlp(corpus[:6000])\n",
    "    \n",
    "    #get_tokens(doc)\n",
    "    #get_entities(doc)\n",
    "    get_sentences(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(doc):\n",
    "    \n",
    "    data_list=[[\"text\",\"text_lower\",\"lemma\",\"lemma_lower\",\"pos\",\"is_alpha\",\"is_stopwors\"]]\n",
    "    \n",
    "    for token in doc:\n",
    "        data_list.append([token.text,token.lower_,token.lemma_,token.lemma_.lower(),token.pos_,token.is_alpha,token.is_stop])\n",
    "        \n",
    "    with open(\"tokens_new.csv\",\"w\",encoding=\"utf-8\",newline=\"\") as token_file:\n",
    "        csv.writer(token_file).writerows(data_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity extraction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(doc):\n",
    "    data_list=[[\"text\",\"text_lower\",\"label\"]]\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        data_list.append([ent.text,ent.lower_,ent.label_])\n",
    "    with open(\"entities.csv\",\"w\",encoding=\"utf-8\",newline=\"\") as entities_file:\n",
    "        csv.writer(entities_file).writerows(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence wise sentiment score extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(doc):\n",
    "    with open(\"positive_words_es.txt\",\"r\",encoding=\"utf-8\") as temp_file:\n",
    "        positive_words=temp_file.read().splitlines()\n",
    "    with open(\"negative_words_es.txt\",\"r\",encoding=\"utf-8\") as temp_file:\n",
    "        negative_words=temp_file.read().splitlines()\n",
    "    data_list=[[\"text\",\"score\"]]\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        if(len(sent.text) >10):\n",
    "            \n",
    "            score=0\n",
    "            \n",
    "            for word in sent:\n",
    "                if word.lower_ in positive_words:\n",
    "                    score+=1\n",
    "                if word.lower_ in negative_words:\n",
    "                    score-=1\n",
    "            data_list.append([       sent.text,score])\n",
    "    \n",
    "    with open(\"sentences_new.csv\",\"w\",encoding=\"utf-8\",newline=\"\") as sentences_file:\n",
    "        csv.writer(sentences_file).writerows(data_list)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
